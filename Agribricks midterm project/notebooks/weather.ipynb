{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73fc5b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary import\n",
    "import pickle # to manipulate models\n",
    "import zipfile # to manipulate .zip file\n",
    "import xgboost as xgb # for gradient boosting classifier\n",
    "import numpy as np # for matrices and numerical manipulations\n",
    "import pandas as pd # for dataframes\n",
    "import matplotlib.pyplot as plt # for plots\n",
    "import seaborn as sns # for visualizing data\n",
    "import matplotlib\n",
    "import sklearn # for machine learning algorithms\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, roc_auc_score, accuracy_score\n",
    "import joblib  # Using joblib instead of pickle for compression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "059ffcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.7\n",
      "seaborn version: 0.13.2\n",
      "xgboost version: 3.1.1\n",
      "sklearn version: 1.6.1\n",
      "pandas version: 2.3.3\n",
      "numpy version: 2.2.6\n"
     ]
    }
   ],
   "source": [
    "# # System versions\n",
    "# print(\"Platform:\", sys.platform)\n",
    "# print(\"Python version:\", sys.version)\n",
    "# print(\"---\" * 47)\n",
    "\n",
    "# Libraries versions\n",
    "print(\"matplotlib version:\", matplotlib.__version__)\n",
    "print(\"seaborn version:\", sns.__version__)\n",
    "print(\"xgboost version:\", xgb.__version__)\n",
    "print(\"sklearn version:\", sklearn.__version__)\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"numpy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bb6e7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(\"../data/merged_aez_weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "73e8b066",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.columns = weather.columns.str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "688135a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_weather = list(weather.dtypes[(weather.dtypes == 'int64') | (weather.dtypes == 'float64')].index)\n",
    "categorical_weather = list(weather.dtypes[weather.dtypes == 'object'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4851932",
   "metadata": {},
   "source": [
    "## Check unique AEZs (different climatic zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3275ba90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Highlands (Humid)', 'Upper Midlands (High Potential)',\n",
       "       'Lower Midlands (Semi-Arid)', 'Coastal Lowlands (Humid)',\n",
       "       'Arid Lowlands (Arid)'], dtype=object)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.aez.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7e9ce6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aez\n",
       "Highlands (Humid)                  11992\n",
       "Upper Midlands (High Potential)    11992\n",
       "Lower Midlands (Semi-Arid)         11992\n",
       "Coastal Lowlands (Humid)           11992\n",
       "Arid Lowlands (Arid)               11992\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.aez.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194a44a5",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "- Convert date and extract temporal features By converting the date column into a datetime format, we can extract useful features such as: month, day of year, week number. These features allow the model to learn seasonal and periodic weather behavior.\n",
    "\n",
    "- Cyclical encoding for month (captures seasonality better)-> Months follow a circular pattern (December → January).\n",
    "Using cyclical encoding: month_sin = sin(2π * month / 12), month_cos = cos(2π * month / 12). This represents seasonality smoothly and avoids misleading jumps (e.g., from 12 to 1). Imagine months arranged in a circle like a clock, instead of hard coding january:1 and December = 12, which makes the model think that january is very far from december while in reality December is next to january in terms of seasonality.\n",
    "\n",
    "- Create lagged features PER AEZ (different zones have different patterns) -> Rainfall patterns differ across Agro-Ecological Zones (AEZs).To capture zone-specific temporal dependencies, lag features were generated separately for each AEZ: Rainfall 1 day ago, Rainfall 3 days ago, Rainfall 7 days ago, Temperature/RH lags, etc. This helps the model learn short-term weather persistence and trends within each zone.\n",
    "\n",
    "- Rolling statistics PER AEZ -> Rolling windows were computed to provide smoothed historical context: Rolling mean (e.g., 7-day or 14-day averages). Rolling standard deviation (captures variability). Again computed by AEZ, because climate behavior differs between zones. These features give the model aggregated context instead of only instantaneous readings.\n",
    "\n",
    "- Fill NaN in std columns (first few rows) -> Rolling statistics produce NaN values for the first few rows (e.g., first 6 records in a 7-day window). These NaNs were filled with 0 for standard deviation: Standard deviation of a single value is effectively 0,Ensures the model receives consistent numeric data.\n",
    "\n",
    "- Drop rows with NaN from lagged features -> Lag features require previous observations. The first several rows for each AEZ do not have enough historical data, so these rows are dropped to avoid: Missing values. Incorrect model training. This preserves data quality.\n",
    "\n",
    "- Binary classification target: Will it rain? (>1mm threshold) -> A classification label was defined: 1 = Yes, it will rain (precipitation > 1 mm), 0 = No, it will not rain. This enables classification models to predict the probability of rainfall, while a separate regressor predicts the amount. Choosing a 1 mm threshold avoids false “rain” labels for negligible drizzle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e95a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert date and extract temporal features\n",
    "weather['date'] = pd.to_datetime(weather['date'])\n",
    "weather['month'] = weather['date'].dt.month\n",
    "weather['day_of_year'] = weather['date'].dt.dayofyear\n",
    "weather['year'] = weather['date'].dt.year\n",
    "weather['week_of_year'] = weather['date'].dt.isocalendar().week.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f636b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclical encoding for month (captures seasonality better)\n",
    "weather['month_sin'] = np.sin(2 * np.pi * weather['month'] / 12)\n",
    "weather['month_cos'] = np.cos(2 * np.pi * weather['month'] / 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b18e0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lagged features PER AEZ (different zones have different patterns)\n",
    "for lag in [1, 3, 7, 14]:\n",
    "    weather[f'rainfall_lag_{lag}'] = weather.groupby('aez')['prectotcorr'].shift(lag)\n",
    "    weather[f'temp_lag_{lag}'] = weather.groupby('aez')['t2m'].shift(lag)\n",
    "    weather[f'humidity_lag_{lag}'] = weather.groupby('aez')['rh2m'].shift(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41304e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling statistics PER AEZ\n",
    "for window in [7, 14, 30]: #roll over 7, 14, and 30 days (ie 1,2,3 and 2,3,4 and 3,4,5 if roll is 3)\n",
    "    weather[f'rainfall_{window}d_avg'] = (\n",
    "        weather.groupby('aez')['prectotcorr']\n",
    "        .rolling(window, min_periods=1).mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    weather[f'rainfall_{window}d_std'] = (\n",
    "        weather.groupby('aez')['prectotcorr']\n",
    "        .rolling(window, min_periods=1).std()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    weather[f'temp_{window}d_avg'] = (\n",
    "        weather.groupby('aez')['t2m']\n",
    "        .rolling(window, min_periods=1).mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6184bf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59960 entries, 0 to 59959\n",
      "Data columns (total 33 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   date               59960 non-null  datetime64[ns]\n",
      " 1   prectotcorr        59960 non-null  float64       \n",
      " 2   t2m                59960 non-null  float64       \n",
      " 3   rh2m               59960 non-null  float64       \n",
      " 4   allsky_sfc_sw_dwn  59960 non-null  float64       \n",
      " 5   aez                59960 non-null  object        \n",
      " 6   month              59960 non-null  int32         \n",
      " 7   day_of_year        59960 non-null  int32         \n",
      " 8   year               59960 non-null  int32         \n",
      " 9   week_of_year       59960 non-null  int64         \n",
      " 10  month_sin          59960 non-null  float64       \n",
      " 11  month_cos          59960 non-null  float64       \n",
      " 12  rainfall_lag_1     59960 non-null  float64       \n",
      " 13  temp_lag_1         59960 non-null  float64       \n",
      " 14  humidity_lag_1     59960 non-null  float64       \n",
      " 15  rainfall_lag_3     59960 non-null  float64       \n",
      " 16  temp_lag_3         59960 non-null  float64       \n",
      " 17  humidity_lag_3     59960 non-null  float64       \n",
      " 18  rainfall_lag_7     59960 non-null  float64       \n",
      " 19  temp_lag_7         59960 non-null  float64       \n",
      " 20  humidity_lag_7     59960 non-null  float64       \n",
      " 21  rainfall_lag_14    59960 non-null  float64       \n",
      " 22  temp_lag_14        59960 non-null  float64       \n",
      " 23  humidity_lag_14    59960 non-null  float64       \n",
      " 24  rainfall_7d_avg    59960 non-null  float64       \n",
      " 25  rainfall_7d_std    59960 non-null  float64       \n",
      " 26  temp_7d_avg        59960 non-null  float64       \n",
      " 27  rainfall_14d_avg   59960 non-null  float64       \n",
      " 28  rainfall_14d_std   59960 non-null  float64       \n",
      " 29  temp_14d_avg       59960 non-null  float64       \n",
      " 30  rainfall_30d_avg   59960 non-null  float64       \n",
      " 31  rainfall_30d_std   59960 non-null  float64       \n",
      " 32  temp_30d_avg       59960 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(27), int32(3), int64(1), object(1)\n",
      "memory usage: 14.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Fill NaN in std columns (first few rows)\n",
    "weather = weather.fillna(0)\n",
    "# Drop rows with NaN from lagged features\n",
    "weather = weather.dropna()\n",
    "\n",
    "weather.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ee5f459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification target: Will it rain? (>1mm threshold)\n",
    "weather['will_rain'] = (weather['prectotcorr'] > 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd5daf4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59960, 34)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c51b881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "will_rain\n",
       "0    0.538442\n",
       "1    0.461558\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.will_rain.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87840cb",
   "metadata": {},
   "source": [
    "##  ENCODING LOCATION (AEZ) - KEY FEATURE FOR KENYA'S DIVERSE CLIMATE\n",
    "- To make the AEZ information usable by machine learning models, it must be encoded into numerical form. Two encoding approaches were used:\n",
    "- Label encoding for AEZ -> Label encoding converts each AEZ category into a unique integer eg coastal -1 highlands -2\n",
    "- One-Hot encoding for AEZ (better for tree-based models) -> One-hot encoding creates one binary column per AEZ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53fb5817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AEZ encoding mapping:\n",
      "  Arid Lowlands (Arid): 0\n",
      "  Coastal Lowlands (Humid): 1\n",
      "  Highlands (Humid): 2\n",
      "  Lower Midlands (Semi-Arid): 3\n",
      "  Upper Midlands (High Potential): 4\n"
     ]
    }
   ],
   "source": [
    "# Label encoding for AEZ\n",
    "le_aez = LabelEncoder()\n",
    "weather['aez_encoded'] = le_aez.fit_transform(weather['aez'])\n",
    "\n",
    "print(f\"AEZ encoding mapping:\")\n",
    "for i, aez in enumerate(le_aez.classes_):\n",
    "    print(f\"  {aez}: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ee990df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded AEZ columns: ['aez_Arid Lowlands (Arid)', 'aez_Coastal Lowlands (Humid)', 'aez_Highlands (Humid)', 'aez_Lower Midlands (Semi-Arid)', 'aez_Upper Midlands (High Potential)']\n"
     ]
    }
   ],
   "source": [
    "# One-Hot encoding for AEZ (better for tree-based models)\n",
    "ohe_aez = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "aez_onehot = ohe_aez.fit_transform(weather[['aez']])\n",
    "aez_onehot_df = pd.DataFrame(\n",
    "    aez_onehot, \n",
    "    columns=[f'aez_{cat}' for cat in ohe_aez.categories_[0]],\n",
    "    index=weather.index\n",
    ")\n",
    "weather = pd.concat([weather, aez_onehot_df], axis=1)\n",
    "\n",
    "print(f\"One-hot encoded AEZ columns: {aez_onehot_df.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf18d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.columns = weather.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d0afb6",
   "metadata": {},
   "source": [
    "## # FEATURE SELECTION -> Focusing on What Truly Drives Weather & Crop Predictions\n",
    "- In weather modeling and crop suitability analysis, selecting the right features is essential for capturing underlying climate behavior, reducing noise, and improving model accuracy.\n",
    "\n",
    "- Features including location (AEZ) - CRITICAL for Kenya's diverse climate -> Because of these strong climatic differences, AEZ becomes one of the most important features in predicting rainfall and recommending crops. Without AEZ, the model would mix together entirely different climate behaviors and lose accuracy.\n",
    "\n",
    "- Add one-hot encoded AEZ columns -> To allow machine-learning models (especially tree-based models like RandomForest and GradientBoosting) to correctly understand AEZ categories, each AEZ is converted into its own binary column using one-hot encoding. Prevents the model from assuming any ordering between AEZ categories, Gives each zone equal opportunity to influence the prediction, Allows the model to learn relationships like: “Coastal areas tend to get more rainfall in March–May”, “Semi-arid zones experience strong dry seasons”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa823885",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features = [\n",
    "    # Climate variables\n",
    "    'T2M', 'RH2M', 'ALLSKY_SFC_SW_DWN',\n",
    "    # Temporal features\n",
    "    'month', 'day_of_year', 'week_of_year',\n",
    "    'month_sin', 'month_cos',\n",
    "    # Location feature (encoded)\n",
    "    'AEZ_encoded',\n",
    "    # Lagged features\n",
    "    'rainfall_lag_1', 'rainfall_lag_3', 'rainfall_lag_7', 'rainfall_lag_14',\n",
    "    'temp_lag_1', 'temp_lag_3', 'temp_lag_7',\n",
    "    'humidity_lag_1', 'humidity_lag_3', 'humidity_lag_7',\n",
    "    # Rolling statistics\n",
    "    'rainfall_7d_avg', 'rainfall_14d_avg', 'rainfall_30d_avg',\n",
    "    'rainfall_7d_std', 'rainfall_14d_std',\n",
    "    'temp_7d_avg', 'temp_14d_avg'\n",
    "]\n",
    "base_features = [feat.lower() for feat in base_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02705614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 36\n",
      "Features:\n",
      "['t2m', 'rh2m', 'allsky_sfc_sw_dwn', 'month', 'day_of_year', 'week_of_year', 'month_sin', 'month_cos', 'aez_encoded', 'rainfall_lag_1', 'rainfall_lag_3', 'rainfall_lag_7', 'rainfall_lag_14', 'temp_lag_1', 'temp_lag_3', 'temp_lag_7', 'humidity_lag_1', 'humidity_lag_3', 'humidity_lag_7', 'rainfall_7d_avg', 'rainfall_14d_avg', 'rainfall_30d_avg', 'rainfall_7d_std', 'rainfall_14d_std', 'temp_7d_avg', 'temp_14d_avg', 'aez_arid lowlands (arid)', 'aez_coastal lowlands (humid)', 'aez_highlands (humid)', 'aez_lower midlands (semi-arid)', 'aez_upper midlands (high potential)', 'aez_arid lowlands (arid)', 'aez_coastal lowlands (humid)', 'aez_highlands (humid)', 'aez_lower midlands (semi-arid)', 'aez_upper midlands (high potential)']\n"
     ]
    }
   ],
   "source": [
    "# Add one-hot encoded AEZ columns\n",
    "aez_columns = [col for col in weather.columns if col.startswith('aez_') and col != 'aez_encoded']\n",
    "feature_cols = base_features + aez_columns\n",
    "\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "print(f\"Features:\\n{feature_cols}\")\n",
    "\n",
    "X = weather[feature_cols]\n",
    "y_classification = weather['will_rain']\n",
    "y_regression = weather['prectotcorr']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f96d29",
   "metadata": {},
   "source": [
    " ## TRAIN-TEST SPLIT\n",
    " - How this train_test_solit works:\n",
    " Step 1: Split X and y_classification together. This gives: X_train_class, X_test_class, y_train_class, y_test_class, Step 2: Split X and y_regression together. This gives: X_train_reg,X_test_reg,y_train_reg,y_test_reg\n",
    " \n",
    " - feature scaling\n",
    " -> Scaling ensures that all numerical features have a consistent range. This is especially important for algorithms that are sensitive to the magnitude of inputs. Scaling puts everything on the same scale, usually 0 to 1 or with mean 0 and variance 1. Why scaling matters: Some features (e.g., temperature) might be around ~20 Others (e.g., solar radiation) might be ~500 Others (e.g., rainfall) can be 0–100+ Without scaling: Large-magnitude features dominate smaller ones. Gradient-based models learn poorly. Convergence becomes slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1210bbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47968, 46) (11992, 46)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_class_train, y_class_test = train_test_split(\n",
    "    X, y_classification, test_size=0.2, random_state=42, stratify=y_classification\n",
    ")\n",
    "_, _, y_reg_train, y_reg_test = train_test_split(\n",
    "    X, y_regression, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed5c3627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365ea41a",
   "metadata": {},
   "source": [
    "### RAINFALL CLASSIFICATION MODELS — Predicting “Will it Rain?”\n",
    "- This classification is based on weather predictors such as temperature, humidity, month, solar radiation, and location (AEZ). Multiple  machine-learning models were evaluated to capture both linear and nonlinear patterns in Kenya’s diverse climate.\n",
    "\n",
    "- 1. Logistic Regression -> Logistic Regression provides a strong baseline for classification. It assumes a linear relationship between the input features and the probability of rainfall.\n",
    "- 2. Random Forest Classifier -> Random Forest is an ensemble of many decision trees.\n",
    "Each tree learns different aspects of rainfall behavior, and the forest combines them to produce a stable prediction.\n",
    "- 3. XGBoost Classifier -> XGBoost is a state-of-the-art boosting algorithm that builds trees sequentially, with each tree correcting the errors of the previous ones.\n",
    "- 4. K-Fold Cross Validation -> Because weather datasets may contain noise, seasonality, and localized climate behavior, K-Fold Cross Validation (CV) is used to reliably estimate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6624f11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8716\n",
      "AUC-ROC: 0.9412\n"
     ]
    }
   ],
   "source": [
    "# 1. Logistic Regression\n",
    "classification_results = {}\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "log_reg.fit(X_train_scaled, y_class_train)\n",
    "y_pred_log = log_reg.predict(X_test_scaled)\n",
    "y_pred_proba_log = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "acc_log = accuracy_score(y_class_test, y_pred_log)\n",
    "auc_log = roc_auc_score(y_class_test, y_pred_proba_log)\n",
    "classification_results['Logistic Regression'] = {'accuracy': acc_log, 'auc': auc_log}\n",
    "print(f\"Accuracy: {acc_log:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_log:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f807dd5",
   "metadata": {},
   "source": [
    "## Random Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8cad2cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_class = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    max_depth=15, \n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff36615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_class.fit(X_train_scaled, y_class_train)\n",
    "y_pred_rf = rf_class.predict(X_test_scaled)\n",
    "y_pred_proba_rf = rf_class.predict_proba(X_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bcf4273a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8772\n",
      "AUC-ROC: 0.9537\n"
     ]
    }
   ],
   "source": [
    "acc_rf = accuracy_score(y_class_test, y_pred_rf)\n",
    "auc_rf = roc_auc_score(y_class_test, y_pred_proba_rf)\n",
    "classification_results['Random Forest'] = {'accuracy': acc_rf, 'auc': auc_rf}\n",
    "print(f\"Accuracy: {acc_rf:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3433025d",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21bdfe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_class = XGBClassifier(\n",
    "    n_estimators=100, \n",
    "    max_depth=6, \n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='auc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a1fc4aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_class.fit(X_train_scaled, y_class_train)\n",
    "y_pred_xgb = xgb_class.predict(X_test_scaled)\n",
    "y_pred_proba_xgb = xgb_class.predict_proba(X_test_scaled)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "be6a7653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8924\n",
      "AUC-ROC: 0.9621\n"
     ]
    }
   ],
   "source": [
    "acc_xgb = accuracy_score(y_class_test, y_pred_xgb)\n",
    "auc_xgb = roc_auc_score(y_class_test, y_pred_proba_xgb)\n",
    "classification_results['XGBoost'] = {'accuracy': acc_xgb, 'auc': auc_xgb}\n",
    "print(f\"Accuracy: {acc_xgb:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20862a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.8933 (+/- 0.0029)\n",
      "CV AUC-ROC: 0.9637 (+/- 0.0017)\n"
     ]
    }
   ],
   "source": [
    "# kfold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores_acc = cross_val_score(xgb_class, X_train_scaled, y_class_train, cv=kfold, scoring='accuracy')\n",
    "cv_scores_auc = cross_val_score(xgb_class, X_train_scaled, y_class_train, cv=kfold, scoring='roc_auc')\n",
    "print(f\"CV Accuracy: {cv_scores_acc.mean():.4f} (+/- {cv_scores_acc.std():.4f})\")\n",
    "print(f\"CV AUC-ROC: {cv_scores_auc.mean():.4f} (+/- {cv_scores_auc.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd94c58",
   "metadata": {},
   "source": [
    "## RAINFALL REGRESSION MODELS (How much rain?)\n",
    "- Because rainfall amounts can vary widely across Kenya’s climatological zones and seasons, multiple regression models were evaluated to capture both simple and complex relationships.\n",
    "\n",
    "1. Linear Regression -> Linear Regression serves as a simple baseline model for predicting rainfall amount based on features such as temperature, humidity, solar radiation, month, and AEZ.\n",
    "\n",
    "2. Random Forest Regressor -> Random Forest Regressor builds many decision trees and averages their predictions.\n",
    "This allows it to capture nonlinear patterns that naturally occur in weather systems.\n",
    "\n",
    "3. XGBoost Regressor -> XGBoost is a powerful gradient boosting framework known for top-tier accuracy.\n",
    "\n",
    "4. K-Fold Cross Validation for regression -> ensures that model evaluation is stable, fair, and robust.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8054b94",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2614a469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5.0885\n",
      "R² Score: 0.0002\n"
     ]
    }
   ],
   "source": [
    "regression_results = {}\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_scaled, y_reg_train)\n",
    "y_pred_lin = lin_reg.predict(X_test_scaled)\n",
    "y_pred_lin = np.maximum(0, y_pred_lin)  # Ensure non-negative\n",
    "\n",
    "rmse_lin = np.sqrt(mean_squared_error(y_reg_test, y_pred_lin))\n",
    "r2_lin = r2_score(y_reg_test, y_pred_lin)\n",
    "regression_results['Linear Regression'] = {'rmse': rmse_lin, 'r2': r2_lin}\n",
    "print(f\"RMSE: {rmse_lin:.4f}\")\n",
    "print(f\"R² Score: {r2_lin:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7e24f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor(\n",
    "    n_estimators=100, \n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d507c63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg.fit(X_train_scaled, y_reg_train)\n",
    "y_pred_rf_reg = rf_reg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "86f716e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5.1060\n",
      "R² Score: -0.0067\n"
     ]
    }
   ],
   "source": [
    "rmse_rf = np.sqrt(mean_squared_error(y_reg_test, y_pred_rf_reg))\n",
    "r2_rf = r2_score(y_reg_test, y_pred_rf_reg)\n",
    "regression_results['Random Forest'] = {'rmse': rmse_rf, 'r2': r2_rf}\n",
    "print(f\"RMSE: {rmse_rf:.4f}\")\n",
    "print(f\"R² Score: {r2_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c6e985",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "49f141da",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = XGBRegressor(\n",
    "    n_estimators=100, \n",
    "    max_depth=6, \n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e8db87e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg.fit(X_train_scaled, y_reg_train)\n",
    "y_pred_xgb_reg = xgb_reg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "263942d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5.1320\n",
      "R² Score: -0.0170\n"
     ]
    }
   ],
   "source": [
    "rmse_xgb = np.sqrt(mean_squared_error(y_reg_test, y_pred_xgb_reg))\n",
    "r2_xgb = r2_score(y_reg_test, y_pred_xgb_reg)\n",
    "regression_results['XGBoost'] = {'rmse': rmse_xgb, 'r2': r2_xgb}\n",
    "print(f\"RMSE: {rmse_xgb:.4f}\")\n",
    "print(f\"R² Score: {r2_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e70626",
   "metadata": {},
   "source": [
    "### Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4af417a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 5.1638 (+/- 0.1980)\n",
      "CV R²: -0.0217 (+/- 0.0038)\n"
     ]
    }
   ],
   "source": [
    "cv_rmse = cross_val_score(xgb_reg, X_train_scaled, y_reg_train, cv=kfold, \n",
    "                          scoring='neg_root_mean_squared_error')\n",
    "cv_r2 = cross_val_score(xgb_reg, X_train_scaled, y_reg_train, cv=kfold, scoring='r2')\n",
    "print(f\"CV RMSE: {-cv_rmse.mean():.4f} (+/- {cv_rmse.std():.4f})\")\n",
    "print(f\"CV R²: {cv_r2.mean():.4f} (+/- {cv_r2.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d800f980",
   "metadata": {},
   "source": [
    "### Feature importance analysis  which features influence the predictions the most.\n",
    "- Check AEZ feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0dc79ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 Most Important Features (XGBoost Classifier):\n",
      "                            feature  importance\n",
      "                     rainfall_lag_1    0.298141\n",
      "                    rainfall_7d_avg    0.135368\n",
      "                    rainfall_7d_std    0.088868\n",
      "                               rh2m    0.069336\n",
      "                     humidity_lag_1    0.030174\n",
      "                          month_cos    0.029336\n",
      "                     humidity_lag_3    0.027136\n",
      "       aez_coastal lowlands (humid)    0.023056\n",
      "                  allsky_sfc_sw_dwn    0.021648\n",
      "                          month_sin    0.020490\n",
      "                     humidity_lag_7    0.019283\n",
      "                     rainfall_lag_3    0.017921\n",
      "              aez_highlands (humid)    0.017686\n",
      "                        aez_encoded    0.016234\n",
      "aez_upper midlands (high potential)    0.014561\n",
      "\n",
      "AEZ (Location) Feature Importance:\n",
      "                            feature  importance\n",
      "       aez_coastal lowlands (humid)    0.023056\n",
      "              aez_highlands (humid)    0.017686\n",
      "                        aez_encoded    0.016234\n",
      "aez_upper midlands (high potential)    0.014561\n",
      "     aez_lower midlands (semi-arid)    0.013612\n",
      "              aez_highlands (humid)    0.012289\n",
      "       aez_coastal lowlands (humid)    0.007389\n",
      "           aez_arid lowlands (arid)    0.000000\n",
      "           aez_arid lowlands (arid)    0.000000\n",
      "     aez_lower midlands (semi-arid)    0.000000\n",
      "aez_upper midlands (high potential)    0.000000\n",
      "           aez_arid lowlands (arid)    0.000000\n",
      "           aez_arid lowlands (arid)    0.000000\n",
      "       aez_coastal lowlands (humid)    0.000000\n",
      "       aez_coastal lowlands (humid)    0.000000\n",
      "              aez_highlands (humid)    0.000000\n",
      "              aez_highlands (humid)    0.000000\n",
      "     aez_lower midlands (semi-arid)    0.000000\n",
      "     aez_lower midlands (semi-arid)    0.000000\n",
      "aez_upper midlands (high potential)    0.000000\n",
      "aez_upper midlands (high potential)    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Feature importance analysis  which features influence the predictions the most.\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': xgb_class.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Most Important Features (XGBoost Classifier):\")\n",
    "print(feature_importance.head(15).to_string(index=False))\n",
    "\n",
    "# Check AEZ feature importance\n",
    "aez_features = feature_importance[\n",
    "    feature_importance['feature'].str.contains('AEZ', case=False)\n",
    "]\n",
    "print(f\"\\nAEZ (Location) Feature Importance:\")\n",
    "print(aez_features.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac6e271",
   "metadata": {},
   "source": [
    "## SELECTING THE BEST Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be200a13",
   "metadata": {},
   "source": [
    "### Classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0b1b73cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Logistic Regression: Accuracy=0.8716, AUC=0.9412\n",
      "  Random Forest: Accuracy=0.8772, AUC=0.9537\n",
      "  XGBoost: Accuracy=0.8924, AUC=0.9621\n"
     ]
    }
   ],
   "source": [
    "for model, metrics in classification_results.items():\n",
    "    print(f\"  {model}: Accuracy={metrics['accuracy']:.4f}, AUC={metrics['auc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea04bd9d",
   "metadata": {},
   "source": [
    "### Regression results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2aa5a600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Linear Regression: RMSE=5.0885, R²=0.0002\n",
      "  Random Forest: RMSE=5.1060, R²=-0.0067\n",
      "  XGBoost: RMSE=5.1320, R²=-0.0170\n"
     ]
    }
   ],
   "source": [
    "for model, metrics in regression_results.items():\n",
    "    print(f\"  {model}: RMSE={metrics['rmse']:.4f}, R²={metrics['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790f4a91",
   "metadata": {},
   "source": [
    "### selecting the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9a159674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Classifier: XGBoost (AUC: 0.9621)\n",
      "Best Regressor: Linear Regression (RMSE: 5.0885)\n"
     ]
    }
   ],
   "source": [
    "# Select best models\n",
    "best_classifier = max(classification_results.items(), key=lambda x: x[1]['auc'])\n",
    "best_regressor = min(regression_results.items(), key=lambda x: x[1]['rmse'])\n",
    "print(f\"\\nBest Classifier: {best_classifier[0]} (AUC: {best_classifier[1]['auc']:.4f})\")\n",
    "print(f\"Best Regressor: {best_regressor[0]} (RMSE: {best_regressor[1]['rmse']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed0325c",
   "metadata": {},
   "source": [
    "## Saving with joblib compression of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2553ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('../../models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d42d03a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/rainfall_feature_columns.joblib']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Save with joblib compression=5 for smaller file sizes (suitable for Render)\n",
    "joblib.dump(xgb_class, '../models/rainfall_classifier.joblib', compress=5)\n",
    "joblib.dump(xgb_reg, '../models/rainfall_regressor.joblib', compress=5)\n",
    "joblib.dump(scaler, '../models/scaler_rainfall.joblib', compress=5)\n",
    "joblib.dump(le_aez, '../models/aez_label_encoder.joblib', compress=5)\n",
    "joblib.dump(ohe_aez, '../models/aez_onehot_encoder.joblib', compress=5)\n",
    "joblib.dump(feature_cols, '../models/rainfall_feature_columns.joblib', compress=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mendyk-Eh3ifHlT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
